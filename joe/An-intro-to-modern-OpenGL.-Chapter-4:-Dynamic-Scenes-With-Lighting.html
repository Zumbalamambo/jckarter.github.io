<!DOCTYPE html>
<html>
<head>
<title>Joe's Blog: An intro to modern OpenGL. Chapter 4: Dynamic Scenes With Lighting</title>
<link rel="stylesheet" href="../durians.css">
<link rel="alternate" type="application/rss+xml" title="Durian Software: Joe's Blog" href="index.rss">
<script src="../durians.js"></script>
</head>
<body class="blog">
<div class="subtitle"><a href="index.html">Joe's blog</a></div>
<a href="../index.html"><img class="marquee" src="../durians.png"></a>
<div class="content">

<div class="sidebar">
<h4>About Me</h4>
<p>My name's Joe Groff, I live in San Francisco, and I'm on a quest to write the great American video game. I mess around with the <a href="http://factorcode.org/">Factor</a> programming language on the side.
<br>
<br><script>male_to('com', 'joe', 'duriansoftware')</script>
<br>twitter <a href="http://twitter.com/jckarter">@jckarter</a>
<br>github <a href="http://github.com/jckarter">jckarter</a>
</p>
<h4>My Friends</h4>
<p>
<a href="http://bugsplat.info/">Peter Keen</a><br>
<a href="http://leto.net/">Jonathan Leto</a><br>
<a href="http://factor-language.blogspot.com/">Slava Pestov</a><br>
<a href="http://profile.myspace.com/index.cfm?fuseaction=user.viewprofile&friendid=189198983">The Summer Darlings</a>
</p>
</div>

<div class="blog">
<h3><a href="http://duriansoftware.com/joe/An-intro-to-modern-OpenGL.-Chapter-4:-Dynamic-Scenes-With-Lighting.html">An intro to modern OpenGL. Chapter 4: Dynamic Scenes With Lighting</a></h3>
<h4>updated July 5, 2010 12:00:46 PDT</h4>
<h4><a href="http://duriansoftware.com/joe/An-intro-to-modern-OpenGL.-Chapter-3:-3D-transformation-and-projection.html">&laquo; Chapter 3</a> | <a href="http://duriansoftware.com/joe/An-intro-to-modern-OpenGL.-Table-of-Contents.html">Table of Contents</a></h4>
<p>At this point, we've seen most of the important parts of the OpenGL API and made . For the next few chapters ...</p>
<p>Perspective projection alone is not enough to render a convincing <span class="smallcap">3d</span> image. Our perception of the texture and contour of something is is primarily influenced by the way light reflects off its surfaces. Simulating the  referred to as <b>shading</b>. Although truly physically accurate light simulation is still only within the reach of supercomputer clusters, ... . Unlike the math of projection, shading is still a subject of active research, and most advances in ... Over the next few chapters we'll implement some common shading techniques. We'll start with Phong shading, a lighting approximation.</p>
<h3>Overview of the <tt>flag</tt> program</h3>
<p>
For this chapter, I've prepared a new demo program you can get from <a href="http://github.com/jckarter/ch4-flag">my Github <tt>ch4-flag</tt> repository</a>. The <tt>flag</tt> demo renders a waving flag on a flagpole against a simple background:
</p>
<center><img src="http://duriansoftware.com/joe/media/gl4-flag.png"></center>
<p>
At this point, it looks like something a Nintendo 64 would render. The grass and brick wall textures appear completely flat, like they've been wallpapered onto flat surfaces. The flagpole doesn't cast any shadow on the ground or wall and floats unnaturally in the scene rather than appearing planted in the ground. We'll improve the graphical fidelity of the demo over the next few chapters. ...
</p>
<p>
The <tt>flag</tt> program contains four C files, but you've already seen much of it in <tt>hello-gl</tt>. The <tt>file-util.c</tt> file contains the <tt>read_tga</tt> and <tt>file_contents</tt> functions from <tt>hello-gl</tt>, and <tt>gl-util.c</tt> contains the <tt>make_texture</tt>, <tt>make_shader</tt>, and <tt>make_program</tt> functions we wrote in chapter 2. <tt>flag.c</tt> looks much like <tt>hello-gl.c</tt> did: we initialize GLUT and GLEW, set up callbacks for GLUT events, allocate a bunch of GL resources, and render our scene. However, the setup and rendering are a bit more involved than last time. Let's look at what's changed:
</p>
<h3>Mesh construction</h3>
<p>
The <tt>meshes.c</tt> file contains code that generates the vertex and element arrays, collectively called a <b>mesh</b>, for the flag, flagpole, ground, and wall objects that we'll be rendering. Most objects in the real world, including real flagpoles and flags, have smooth curving surfaces, but graphics cards deal with triangles, so to render these objects, we have to approximate their surfaces as a collection of triangles. We do this by filling the vertex array with vertices placed along its surface, storing attributes of the surface with each vertex, and connecting the samples into triangles using the element array so those attributes get interpolated between vertices to give an approximation of the original surface.
</p>
<pre>mesh diagram</pre>
<p>The fundamental properties a mesh stores for each vertex are its <b>position</b> in world space and its <b>normal</b>, a vector perpendicular to the original surface at the sample point that indicates the way it faces. The normal is fundamental to shading calculations, as we'll see shortly. Normals should be <b>unit vectors</b>, that is, vectors whose length is one. Each vertex also has <b>material</b> information that further indicates how the surface is shaded, including its color and shininess. Usually the material data consists of one or more <b>texture coordinates</b> that map the vertex to a position on a texture. <p>For <tt>flag</tt>, the vertices store the position, normal, a texture coordinate, and a <b>specular</b> color and <b>shininess</b> factor we'll use in shading. Our vertex buffer thus contains an array of <tt>flag_vertex</tt> structs looking like this:</p>
<pre>struct flag_vertex {
    GLfloat position[4];
    GLfloat normal[4];
    GLfloat texcoord[2];
    GLfloat shininess;
    GLubyte specular[4];
};</pre>
<p>Although the position and normal are three-dimensional vectors, we pad them out to four elements because GPUs prefer to load vector data from 128-bit-aligned buffers, much like SIMD instruction sets such as SSE. The extra <tt>_pad_</tt> field serves the same purpose. For each mesh, we collect the vertex buffer, element buffer, texture object, and element count into a <tt>flag_mesh</tt> struct. When we render, we set up <tt>glVertexAttribPointer</tt>s to pass all of these attributes to the vertex shader:</p>
<pre> struct flag_mesh {
    GLuint vertex_buffer, element_buffer;
    GLsizei element_count;
    GLuint texture;
};</pre>
<pre>static void render_mesh(struct flag_mesh const *mesh)
{
    glBindTexture(GL_TEXTURE_2D, mesh->texture);

    glBindBuffer(GL_ARRAY_BUFFER, mesh->vertex_buffer);
    glVertexAttribPointer(
        g_resources.flag_program.attributes.position,
        3, GL_FLOAT, GL_FALSE, sizeof(struct flag_vertex),
        (void*)offsetof(struct flag_vertex, position)
    );
    glVertexAttribPointer(
        g_resources.flag_program.attributes.normal,
        3, GL_FLOAT, GL_FALSE, sizeof(struct flag_vertex),
        (void*)offsetof(struct flag_vertex, normal)
    );
    glVertexAttribPointer(
        g_resources.flag_program.attributes.texcoord,
        2, GL_FLOAT, GL_FALSE, sizeof(struct flag_vertex),
        (void*)offsetof(struct flag_vertex, texcoord)
    );
    glVertexAttribPointer(
        g_resources.flag_program.attributes.shininess,
        1, GL_FLOAT, GL_FALSE, sizeof(struct flag_vertex),
        (void*)offsetof(struct flag_vertex, shininess)
    );
    glVertexAttribPointer(
        g_resources.flag_program.attributes.specular,
        4, GL_UNSIGNED_BYTE, GL_TRUE, sizeof(struct flag_vertex),
        (void*)offsetof(struct flag_vertex, specular)
    );

    glBindBuffer(GL_ELEMENT_ARRAY_BUFFER, mesh->element_buffer);
    glDrawElements(
        GL_TRIANGLES,
        mesh->element_count,
        GL_UNSIGNED_SHORT,
        (void*)0
    );
}</pre>
<p>The code to generate the meshes themselves is fairly tedious, so I'll just describe it at a high level. We construct two distinct meshes: the background mesh, created by <tt>init_background_mesh</tt>, which consists of the static flagpole, ground, and wall objects; and the flag, set up by <tt>init_flag_mesh</tt>. (Keeping the flag mesh separate makes it easy to stream new vertex data into its vertex buffer as it animates and to render it with its own texture file.) The background mesh consists of two large rectangles for the ground and wall, and a cylinder with a pointed truck on top for the flagpole. The wall, ground, and flagpole are assigned texture coordinates to sample out of a single <b>texture atlas</b> containing the grass, brick, and metal textures, allowing the entire background to be rendered in a single pass with the same texture bound. The flagpole is additionally given a yellow specular color, which will give it a metallic sheen when we shade it. The flag is generated by evaluating the function <tt>calculate_flag_vertex</tt> at regular intervals between zero and one on the <i>s</i> and <i>t</i> parametric axes, generating something that looks sort of like a flag flapping in the breeze.</p>
<h3>Streaming dynamic mesh data</h3>
<pre>void update_flag_mesh(
    struct flag_mesh const *mesh,
    struct flag_vertex *vertex_data,
    GLfloat time
) {
    GLsizei s, t, i;
    for (t = 0, i = 0; t &lt; FLAG_Y_RES; ++t)
        for (s = 0; s &lt; FLAG_X_RES; ++s, ++i) {
            GLfloat ss = FLAG_S_STEP * s, tt = FLAG_T_STEP * t;

            calculate_flag_vertex(&vertex_data[i], ss, tt, time);
        }

    glBindBuffer(GL_ARRAY_BUFFER, mesh->vertex_buffer);
    glBufferData(
        GL_ARRAY_BUFFER,
        FLAG_VERTEX_COUNT * sizeof(struct flag_vertex),
        vertex_data,
        GL_STREAM_DRAW
    );
}</pre>
<p>To animate the flag, we use our <tt>glutIdleFunc</tt> callback to recalculate the flag's vertices and update the contents of the vertex buffer. We do this using the same <tt>glBufferData</tt> function we use to initialize our static background vertex buffer. However, we give the flag vertex data the <tt>GL_STREAM_DRAW</tt> hint instead of the <tt>GL_STATIC_DRAW</tt> hint we've been using until now. This tells the OpenGL driver to optimize for the fact that we'll be continuously replacing the buffer with new data. Since the connectivity of the vertices doesn't need to change, only the positions and normals of the vertices themselves, the element buffer for the flag can remain static. We only need to update the vertex buffer.</p>
<h3>Updating the projection matrix and viewport</h3>
<p>If you go back a chapter and try resizing the <tt>hello-gl</tt> window, you'll notice that the image stretches to fit the new size of the window, ruining the aspect ratio we worked so hard to preserve. In order to maintain an accurate aspect ratio, we have to recalculate our projection matrix when the window size changes, taking the new aspect ratio into account. We also have to inform OpenGL of the new viewport size by calling <tt>glViewport</tt>. GLUT allows us to provide a callback that gets invoked when the window is resized using glutReshapeFunc:
<pre>reshape and update_p_matrix functions</pre>
<p>That covers most of the new things the C code for the <tt>flag</tt> demo does. The actual shading happens inside the shader code, which we'll look at next.</p>

<h3>Phong shading</h3>
<p>Physically accurate light simulation requires expensive algorithms that only recently have started to become possible for high-end machines to calculate in real-time. Fortunately, human eyes don't require perfect physical accuracy, and real-time computer graphics has come a long way on typical consumer hardware by using cheap tricks that approximate the behavior of light without simulating it perfectly. The most fundamental of these tricks is the <b>Phong shading model</b>, an inexpensive approximation of how light interacts with simple materials developed by computer graphics pioneer Bui Tuong Phong in the early 1970s. Phong shading is a <b>local illumination</b> simulation&mdash;it only considers the direct interaction between a light source and a single point. Because of this, Phong shading alone cannot calculate effects that involve the influence of other objects in a scene, such as shadows and mirror reflections. This is why the flag casts no shadow on the ground or wall behind it.</p>
<p>
<pre>Phong diagram</pre>
<p>
The Phong model involves three different lighting terms:
</p>
<ul>
<li><b>ambient</b> reflection, a constant term that simulates the background level of light in the scene that illuminates directly unlighted surfaces;</li>
<li><b>diffuse</b> reflection, the light reflected evenly off the surface, giving the material what we usually think of as its color;</li>
<li>and <b>specular</b> reflection, the shine of polished or metallic surfaces.
</ul>
<p>Phong shading calculates these terms for a point on a surface from the material attributes of the light sources and object surface. These material attributes include color values for the diffuse, ambient, and specular effects. Phong calculations also require unit vectors indicating the direction from the surface to each light source, the direction from the surface to the viewer, and the surface normal.

<h3>Diffuse and ambient reflection</h3>
<pre>diffuse diagram</pre>
<p>If you hold a flat sheet of paper up to a lamp in a dark room, it will appear brightest when it faces the lamp head-on, and appear dimmer as you rotate it away from the light, reaching its darkest when it's perpendicular to the light. Curved surfaces behave the same way; if you roll up or crumple the paper, its surface will be brightest where it faces the light the most directly. The wider the angle between the surface normal and the light direction, the darker the paper appears. Also, If the paper and light remain stationary but your head moves, the paper's perceived color and brightness won't change, because it reflects light evenly in every direction, or "diffusely." This basic lighting effect is called <b>diffuse reflection</b>.</p>
<p>
Vector analysis provides an operation called the <b>dot product</b> that measures the angle between two vectors. Given two unit vectors, a dot product of one means the vectors face the exact same direction, zero means they're perpendicular, and negative one means they face exact opposite directions. This mirrors the behavior of diffuse reflection: surfaces parallel to a light source reflect the most light, while perpendicular surfaces reflect the least. Phong shading thus determines the diffuse reflection factor by taking the dot product of the surface normal and the direction from the surface to the light source. If the dot product is greater than zero, it is multiplied by the diffuse color of the light, and the result is multiplied with the surface diffuse color and added into the surface color.
</p>
<p>
Even when a surface isn't directly lit, it's still not entirely dark. In any enclosed space, there will be a certain amount of ambient light reflecting around, illuminating surfaces that are not otherwise lit. The Phong model simulates this by assigning a constant ambient term to light sources which gets added to the light's diffuse color after it's been multiplied by the dot product. The calculation for ambient and diffuse light thus looks like this:
</p>
<pre>diffuse + ambient formula</pre>

<h3>Specular reflection</h3>
<pre>specular diagram</pre>
<p>Not all surfaces reflect light uniformly; many materials, including metals, glass, hair, and skin, have a reflective sheen. Unlike diffuse reflection, if the viewer moves while a light source and shiny object remain stationary, the shine will move along the surface with the viewer. Physically, an object appears shiny when its surface is covered in highly reflective <b>microfacets</b>. These facets face every direction, creating a bright shiny spot where the light source reflects directly toward the viewer. This effect is called <b>specular reflection</b>.</p>
<p>The specular effect is caused by reflection from the light source to the viewer, so Phong shading simulates the specular effect by reflecting the light direction around the surface normal to give a reflection direction. We can then take the dot product of the reflection direction and the direction from the surface to the viewer. Microfacets on a specular surface follow a <b>normal distribution</b>: a plurality of facets lie parallel to the surface, and there is an exponential dropoff in the number of facets at steeper angles from the surface. The dropoff is sharper for more polished surfaces, giving a smaller, tighter specular highlight. Phong shading approximates this distribution by raising the dot product to an exponent called the <b>shininess factor</b>, with higher shininess factors giving a more polished shine and lower factors giving a more diffuse sheen. This final specular factor is then multiplied by the specular colors of the light source and surface, and the result added to the diffuse and ambient colors to give the final color:</p>
<pre>diffuse + ambient + specular formula</pre>

<h3>Implementing Phong shading</h3>
<p>
Shading calculations are usually performed in the vertex and fragment shaders, where they can leverage the GPU's parallel processing power. (This is where the term "shader" for GPU programs comes from.) Shading can be performed either at a per-vertex or per-fragment level: the former saves computation time by calculating diffuse, ambient, and specular terms only at a per-vertex level and letting the values be interpolated over triangle surfaces, but has poorer accuracy. Modern GPUs are powerful enough that per-fragment shading is preferable, so that's what I've done for <tt>flag</tt>. The vertex shader, <tt>flag.v.glsl</tt>, thus only performs transformation and projection and forwards the material attributes to varying variables for the fragment shader:
</p>
<pre>#version 110

uniform mat4 p_matrix, mv_matrix;
uniform sampler2D texture;

attribute vec3 position, normal;
attribute vec2 texcoord;
attribute float shininess;
attribute vec4 specular;

varying vec3 frag_position, frag_normal;
varying vec2 frag_texcoord;
varying float frag_shininess;
varying vec4 frag_specular;

void main()
{
    vec4 eye_position = mv_matrix * vec4(position, 1.0);
    gl_Position = p_matrix * eye_position;
    frag_position = eye_position.xyz;
    frag_normal   = (mv_matrix * vec4(normal, 0.0)).xyz;
    frag_texcoord = texcoord;
    frag_shininess = shininess;
    frag_specular = specular;
}</pre>
<p>In addition to the texture coordinate, shininess, and specular color we forward directly from the vertex attributes, we also pass to the fragment shader the position as transformed by the modelview matrix, from which we can determine the surface-to-viewer direction, and the transformed normal vector. Since the normal is a directional vector without a position, we apply the matrix to it with a <i>w</i> component of zero, which cancels out the translation of the matrix and only applies its rotation. With these varying values, the fragment shader, <tt>flag.f.glsl</tt>, can perform the actual Phong calculation:</p>
<pre>#version 110

uniform mat4 p_matrix, mv_matrix;
uniform sampler2D texture;

varying vec3 frag_position, frag_normal;
varying vec2 frag_texcoord;
varying float frag_shininess;
varying vec4 frag_specular;

const vec3 light_direction = vec3(0.408248, -0.816497, 0.408248);
const vec4 light_diffuse = vec4(0.8, 0.8, 0.8, 0.0);
const vec4 light_ambient = vec4(0.2, 0.2, 0.2, 1.0);
const vec4 light_specular = vec4(1.0, 1.0, 1.0, 1.0);

void main()
{
    vec3 light_eye_direction = (mv_matrix * vec4(light_direction, 0.0)).xyz,
         normal = normalize(frag_normal),
         eye = normalize(frag_position),
         reflection = reflect(light_eye_direction, normal);

    vec4 color = texture2D(texture, frag_texcoord);
    float diffuse = max(-dot(normal, light_eye_direction), 0.0);
    float spec = max(pow(-dot(reflection, eye), frag_shininess), 0.0);
    
    gl_FragColor = spec * frag_specular * light_specular
        + color * (light_diffuse * diffuse + light_ambient);
}</pre>
<p>The fragment shader uses a few new GLSL functions we haven't seen before:</p>
<ul>
<li><tt>normalize(v)</tt> returns a unit vector with the same direction as <tt>v</tt>. We use it here to convert the fragment position into a direction vector, and to ensure that the normal is a unit vector. Even if our original vertex normals are all unit vectors, their linear interpolations won't be.</li>
<li><tt>dot(u,v)</tt> returns the dot product of two vectors, <tt>u</tt> and <tt>v</tt>, which we use to determine the diffuse and specular factors.</li>
<li><tt>pow(x,n)</tt> raises <tt>x</tt> to the <tt>n</tt>th power, which we use to apply the specular shininess factor.</li>
<li><tt>max(n,m)</tt> returns the larger of <tt>n</tt> or <tt>m</tt>. This lets us clamp dot products less than zero&mdash;if a surface faces away from a light source, it's not going to be affected by it at all.</li>
<li><tt>reflect(u,v)</tt> reflects the vector <tt>u</tt> around <tt>v</tt>, giving a vector with the same angle offset from <tt>v</tt> in the opposite direction <tt>u</tt>. With it we derive the reflection direction from the light direction and surface normal.</li>
<pre>reflect diagram</pre></li>
</ul>
<p>The fragment shader should be easy to follow in light of the Phong shading formula I explained above. We transform our constant light direction to put it in the same coordinate space as our normal and eye position from the vertex shader, and sample the surface's diffuse color from the mesh texture. We then apply the Phong formula, using the <tt>normal</tt>, <tt>light_eye_direction</tt>, <tt>reflection</tt>, and <tt>eye</tt> vectors gleaned from our vertex attributes, and assign the shaded color value to <tt>gl_FragColor</tt> to generate the final shaded fragment.</p>

<h4><a href="http://duriansoftware.com/joe/An-intro-to-modern-OpenGL.-Chapter-3:-3D-transformation-and-projection.html">&laquo; Chapter 3</a> | <a href="http://duriansoftware.com/joe/An-intro-to-modern-OpenGL.-Table-of-Contents.html">Table of Contents</a></h4>

</div>

<div class="cleared"></div>
<br><script>male_to('com', 'joe', 'duriansoftware', 'Email me')</script>
<br><a class="archives" href="archives.html">Archives</a>

<div style="clear:both"></div>
</div>

<div class="fineprint">
&copy; 2010 Durian Software. | <a href="../contact.html">Contact Us</a>
</div>
</body>
</html>
